#! /bin/bas

source ./ceph-cluster-settings

function generate_conf {
	cat <<EOC > conf
public network = $NETWORK_IP.0/$NETWORK_MASK
cluster network = $NETWORK_IP.0/$NETWORK_MASK

#Choose reasonable numbers for number of replicas and placement groups.
osd pool default size = 2 # Write an object 2 times
osd pool default min size = 1 # Allow writing 1 copy in a degraded state
osd pool default pg num = 256
osd pool default pgp num = 256

#Choose a reasonable crush leaf type
#0 for a 1-node cluster.
#1 for a muGlti node cluster in a single rack
#2 for a multi node, multi chassis cluster with multiple hosts in a chassis
#3 for a multi node cluster with hosts across racks, etc.
osd crush chooseleaf type = 1
EOC

}

function generate_deploy_script {
	cat <<EOT > ceph-cluster-deploy
#! /bin/bash

ceph-deploy install $nodes
sleep 1

echo "AICIIIIIIIIIIIIIIIIIIIIII Pune si TU noile binare!!!"
read

mkdir ceph-deploy
cd ceph-deploy

cat ~/conf >> ceph.conf
cat ceph.conf
ceph-deploy new mon1 mon2 mon3
ceph-deploy mon create-initial
ceph-deploy gatherkeys mon1
sleep 1

ceph-deploy disk zap osd1:loop0 osd1:loop1 osd1:loop2
ceph-deploy osd create osd1:loop0:/dev/loop3p1 osd1:loop1:/dev/loop3p2 osd1:loop2:/dev/loop3p3
sleep 1

ceph-deploy disk zap osd2:loop4 osd2:loop5 osd2:loop6
ceph-deploy osd create osd2:loop4:/dev/loop7p1 osd2:loop5:/dev/loop7p2 osd2:loop6:/dev/loop7p3
sleep 1

ceph-deploy disk zap osd3:loop8 osd3:loop9 osd3:loop10
ceph-deploy osd create osd3:loop8:/dev/loop11p1 osd3:loop9:/dev/loop11p2 osd3:loop10:/dev/loop11p3
sleep 1

ceph-deploy admin $nodes
sudo chmod +r /etc/ceph/ceph.client.admin.keyring
sleep 1

ssh osd1 "sudo sgdisk -t 1:45b0969e-9b03-4f30-b4c6-b4b80ceff106 /dev/loop3 && sudo sgdisk -t 2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 /dev/loop3 && sudo sgdisk -t 3:45b0969e-9b03-4f30-b4c6-b4b80ceff106 /dev/loop3"
ssh osd2 "sudo sgdisk -t 1:45b0969e-9b03-4f30-b4c6-b4b80ceff106 /dev/loop7 && sudo sgdisk -t 2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 /dev/loop7 && sudo sgdisk -t 3:45b0969e-9b03-4f30-b4c6-b4b80ceff106 /dev/loop7"
ssh osd3 "sudo sgdisk -t 1:45b0969e-9b03-4f30-b4c6-b4b80ceff106 /dev/loop11 && sudo sgdisk -t 2:45b0969e-9b03-4f30-b4c6-b4b80ceff106 /dev/loop11 && sudo sgdisk -t 3:45b0969e-9b03-4f30-b4c6-b4b80ceff106 /dev/loop11"

ssh osd1 "sudo systemctl enable ceph-osd.target && sudo systemctl start ceph-osd.target && sudo systemctl status ceph-osd.target"
ssh osd2 "sudo systemctl enable ceph-osd.target && sudo systemctl start ceph-osd.target && sudo systemctl status ceph-osd.target"
ssh osd3 "sudo systemctl enable ceph-osd.target && sudo systemctl start ceph-osd.target && sudo systemctl status ceph-osd.target"

ssh mon1 "sudo systemctl enable ceph-mon.target && sudo systemctl start ceph-mon.target && sudo systemctl status ceph-mon.target"
ssh mon2 "sudo systemctl enable ceph-mon.target && sudo systemctl start ceph-mon.target && sudo systemctl status ceph-mon.target"
ssh mon3 "sudo systemctl enable ceph-mon.target && sudo systemctl start ceph-mon.target && sudo systemctl status ceph-mon.target"

cat << EndOfHelp

*******************************************************
Ceph cluster created.
Now restart the cluster by running:
	./stop_cluster.sh && ./start_cluster.sh
on the host system in the docker-ceph-cluster dyrectory
*******************************************************

EndOfHelp
EOT

	chmod +x ceph-cluster-deploy
}

function ceph_services_stop {
	for node in $nodes; do
		ssh root@$node "sudo systemctl stop ceph-osd.target"
		ssh root@$node "sudo systemctl stop ceph-mon.target"
		ssh root@$node "sudo systemctl stop ceph"
	done
}

function ceph_services_start {
	for node in $nodes; do
		ssh root@$node "sudo systemctl start ceph-osd.target"
		ssh root@$node "sudo systemctl start ceph-mon.target"
		ssh root@$node "sudo systemctl start ceph"
	done
}

debs[1]="ceph_10.2.2-1_amd64.deb"
debs[2]="ceph-base_10.2.2-1_amd64.deb"
debs[3]="ceph-common_10.2.2-1_amd64.deb"
debs[4]="ceph-mds_10.2.2-1_amd64.deb"
debs[5]="ceph-mon_10.2.2-1_amd64.deb"
debs[6]="ceph-osd_10.2.2-1_amd64.deb"
debs[7]="libcephfs1_10.2.2-1_amd64.deb"
debs[8]="python-cephfs_10.2.2-1_amd64.deb"

function is_necessary_deb {
	for ((i = 1; i <= ${#debs[@]}; i++)); do
		if [$1 = ${debs[$1]}]; then
			return 0;
		fi
	done
	return -1
}

function copy_debs {
	MODULE="INSTALL_DEBS"
	DEB_PATH=$1
	FILES="$DEB_PATH/*.deb"

	for node in $nodes; do
		log $MODULE "Copy .deb files from folder $DEB_PATH to node $node"
		ssh $node 'mkdir -p debs'
		for file in $FILES; do
			is_necessary_deb "$file" && echo $file
		done
		#scp $file  $node:./debs/
	done
}

